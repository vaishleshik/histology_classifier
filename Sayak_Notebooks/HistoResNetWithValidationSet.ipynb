{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.misc import imresize\n",
    "from scipy.misc import imshow\n",
    "from scipy.misc import imread\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For fixing the randomness and thereby enabling my team members to reproduce the experiments\n",
    "np.random.seed(7)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_csv = pd.read_csv('data_chec_resized/dat.csv', sep=',')\n",
    "filename_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniforming the precision to half sp as to speed up the training (NVIDIA inspired)\n",
    "temp = []\n",
    "for img_name in filename_csv.filename:\n",
    "    img_path = os.path.join('data_chec_resized', 'pool', img_name)\n",
    "    img = imread(img_path)\n",
    "    img = imresize(img, (256,192))\n",
    "    #img = img.astype('float32') \n",
    "    temp.append(img)\n",
    "\n",
    "X = np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y = lb.fit_transform(filename_csv['label'])\n",
    "y = keras.utils.np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rescale=1 / 255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.05,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    " \n",
    "# Initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug.fit(X_train)\n",
    "train_generator = trainAug.flow(X_train, y_train, batch_size=32)\n",
    "                                     \n",
    "valAug.fit(X_test)\n",
    "valid_generator = valAug.flow(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 64\n",
    "INIT_LR = 1e-1\n",
    "BS = 32\n",
    "def poly_decay(epoch):\n",
    "    maxEpochs = NUM_EPOCHS\n",
    "    baseLR = INIT_LR\n",
    "    power = 1.0\n",
    " \n",
    "    alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    " \n",
    "    # return the new learning rate\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our ResNet model\n",
    "from resnet import ResNet\n",
    "model = ResNet.build(192, 256, 3, 8, (3, 4, 6),\n",
    "                    (16, 32, 64, 128), reg=0.0005)\n",
    "\n",
    "# Define the optimizer (other variants are also needed to be tried)\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "opt = RMSprop(lr=0.01)\n",
    "\n",
    "# Compile the model to optimize the categorical_crossentropy as the loss function\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import EarlyStopping, TensorBoard, LearningRateScheduler\n",
    "\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=5), \\\n",
    "#              TensorBoard(log_dir='./logs'), \\\n",
    "#              LearningRateScheduler(poly_decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [TensorBoard(log_dir='./logs'), \\\n",
    "#              LearningRateScheduler(poly_decay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"ResNet Model Weights/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "H = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=2,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=2,\n",
    "    epochs=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = 64\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(10,5))\n",
    "# plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"uppoer right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict_on_batch(X_test)\n",
    "print(accuracy_score(y_test, predictions) * 100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "vgg_conv = VGG16(weights='imagenet',include_top=False,input_shape=(256, 192, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats=vgg_conv.predict(X_train)\n",
    "print(train_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_feats, (X_train.shape[0], 8 * 6 * 512))\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "multi_label_logreg = ClassifierChain(logreg)\n",
    "multi_label_logreg.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = vgg_conv.predict(X_test)\n",
    "print(test_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = np.reshape(test_feats, (X_test.shape[0], 8 * 6 * 512))\n",
    "predictions = multi_label_logreg.predict(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,predictions) * 100.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
